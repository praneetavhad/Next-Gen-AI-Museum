{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17250eee-2d89-4dd1-953c-7c425e70d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=5, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=5, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=5, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=5, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=5, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=5, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=10, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=10, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=10, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=10, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=10, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=10, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=20, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=20, min_samples_split=2\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=20, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=20, min_samples_split=10\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Gini, max_depth=20, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Training: Entropy, max_depth=20, min_samples_split=20\n",
      "========================================\n",
      "\n",
      "Best Model: gini_d10_s20 with accuracy: 0.7400\n",
      "Description: Gini, max_depth=10, min_samples_split=20\n",
      "\n",
      "Confusion Matrix for Best Model (gini_d10_s20):\n",
      "[[76 24]\n",
      " [28 72]]\n",
      "\n",
      "Classification Report for Best Model (gini_d10_s20):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       100\n",
      "           1       0.75      0.72      0.73       100\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.74      0.74      0.74       200\n",
      "weighted avg       0.74      0.74      0.74       200\n",
      "\n",
      "\n",
      "Decision Tree training complete. All results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define dataset paths (assuming train.txt and val.txt are in the same directory as the notebook)\n",
    "train_file = \"train.txt\"\n",
    "val_file = \"val.txt\"\n",
    "\n",
    "# Ensure results directories exist\n",
    "results_dir = \"results/decision_tree\"\n",
    "classification_reports_dir = os.path.join(results_dir, \"classification_reports\")\n",
    "confusion_matrices_dir = os.path.join(results_dir, \"confusion_matrices\")\n",
    "models_dir = \"models\"\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(classification_reports_dir, exist_ok=True)\n",
    "os.makedirs(confusion_matrices_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Load Data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load image paths and labels from a dataset file.\"\"\"\n",
    "    paths, labels = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            img_path = line.strip()\n",
    "            if os.path.exists(img_path):\n",
    "                category = img_path.split('/')[1]  # Adjust based on your file structure\n",
    "                paths.append(img_path)\n",
    "                labels.append(category)\n",
    "    return pd.DataFrame({'image': paths, 'label': labels})\n",
    "\n",
    "train_df = load_data(train_file)\n",
    "val_df = load_data(val_file)\n",
    "\n",
    "# Feature extraction (example: histogram features)\n",
    "def compute_histogram_features(img_path):\n",
    "    \"\"\"Extracts histogram features from an image.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (64, 64))  # Resize for consistency\n",
    "    hist_features = [cv2.calcHist([img], [i], None, [256], [0, 256]).flatten() for i in range(3)]\n",
    "    return np.concatenate(hist_features)\n",
    "\n",
    "# Compute features for training and validation data\n",
    "X_train = np.array([compute_histogram_features(path) for path in train_df['image']])\n",
    "X_val = np.array([compute_histogram_features(path) for path in val_df['image']])\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['label'])\n",
    "y_val = label_encoder.transform(val_df['label'])\n",
    "\n",
    "# Define hyperparameter configurations for comparison\n",
    "HYPERPARAM_CONFIGS = []\n",
    "depth_values = [5, 10, 20]  # Shallow and Deep Trees\n",
    "split_values = [2, 10, 20]  # Different min_samples_split values\n",
    "\n",
    "for depth in depth_values:\n",
    "    for split in split_values:\n",
    "        for criterion in [\"gini\", \"entropy\"]:\n",
    "            HYPERPARAM_CONFIGS.append({\n",
    "                'name': f\"{criterion}_d{depth}_s{split}\",\n",
    "                'criterion': criterion,\n",
    "                'max_depth': depth,\n",
    "                'min_samples_leaf': 5,  # Keeping this constant\n",
    "                'min_samples_split': split,  # Varying this value\n",
    "                'class_weight': 'balanced',\n",
    "                'description': f\"{criterion.capitalize()}, max_depth={depth}, min_samples_split={split}\"\n",
    "            })\n",
    "\n",
    "# Function to evaluate and save results\n",
    "def evaluate_and_save(model, X_val, y_val, config_name, description, results_dir):\n",
    "    \"\"\"Evaluate the model and save results.\"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    # Save classification report\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(classification_reports_dir, f\"{config_name}_report.csv\"))\n",
    "    \n",
    "    # Save confusion matrix plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {description}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(confusion_matrices_dir, f\"{config_name}_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(models_dir, f\"{config_name}_model.pkl\"))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# List to store models with their configurations\n",
    "models_list = []\n",
    "\n",
    "# Train and evaluate models\n",
    "all_metrics = []\n",
    "\n",
    "for config in HYPERPARAM_CONFIGS:\n",
    "    print(f\"\\n{'=' * 40}\")\n",
    "    print(f\"Training: {config['description']}\")\n",
    "    print(f\"{'=' * 40}\")\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=config['criterion'],\n",
    "        max_depth=config['max_depth'],\n",
    "        min_samples_leaf=config['min_samples_leaf'],\n",
    "        min_samples_split=config['min_samples_split'],\n",
    "        class_weight=config['class_weight'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate and Save results\n",
    "    accuracy = evaluate_and_save(model, X_val, y_val, config['name'], config['description'], results_dir)\n",
    "    \n",
    "    # Store metrics and model in the models list\n",
    "    all_metrics.append({\n",
    "        'config_name': config['name'],\n",
    "        'description': config['description'],\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "    models_list.append({\n",
    "        'config_name': config['name'],\n",
    "        'model': model\n",
    "    })\n",
    "\n",
    "# Save final results\n",
    "comparative_df = pd.DataFrame(all_metrics)\n",
    "comparative_df.to_csv(os.path.join(results_dir, \"model_comparison.csv\"), index=False)\n",
    "\n",
    "# # Plot accuracy comparisons\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='config_name', y='accuracy', data=comparative_df)\n",
    "# plt.title('Accuracy Comparison of Decision Tree Configurations')\n",
    "# plt.xlabel('Configuration')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(results_dir, \"accuracy_comparison.png\"))\n",
    "# plt.show()\n",
    "\n",
    "# Save best model characteristics\n",
    "best_model = comparative_df.loc[comparative_df['accuracy'].idxmax()]\n",
    "print(f\"\\nBest Model: {best_model['config_name']} with accuracy: {best_model['accuracy']:.4f}\")\n",
    "print(f\"Description: {best_model['description']}\")\n",
    "\n",
    "with open(os.path.join(results_dir, \"best_model_summary.txt\"), \"w\") as f:\n",
    "    f.write(f\"Best Model: {best_model['config_name']}\\n\")\n",
    "    f.write(f\"Accuracy: {best_model['accuracy']:.4f}\\n\")\n",
    "    f.write(f\"Description: {best_model['description']}\\n\")\n",
    "\n",
    "# Extract confusion matrix for the best model\n",
    "best_model_info = next(model_info for model_info in models_list if model_info['config_name'] == best_model['config_name'])\n",
    "cm = confusion_matrix(y_val, best_model_info['model'].predict(X_val))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(f\"\\nConfusion Matrix for Best Model ({best_model['config_name']}):\")\n",
    "print(cm)\n",
    "\n",
    "# Print classification report\n",
    "y_pred_best = best_model_info['model'].predict(X_val)\n",
    "report = classification_report(y_val, y_pred_best)\n",
    "print(f\"\\nClassification Report for Best Model ({best_model['config_name']}):\")\n",
    "print(report)\n",
    "\n",
    "print(\"\\nDecision Tree training complete. All results saved successfully!\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9bd07-5316-4b7f-9649-e21f7f219fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
